--- Common Steps ---
# 3.2 Installing Hadoop and setting Environment Variables

1. Set up SDKMAN! and default java version as 1.8.

1. Download Hadoop .tar.gz file. Ensure it is the binary and not the soure file. Here, we'll be using v3.2.1 of the Hadoop Binary.
	
1. Unpack the archive with tar, while redirecting the output to /opt directory:
> `sudo tar -xvf hadoop-3.2.1.tar.gz  -C /opt/`
 
1. Remove the archive file and then move to the /opt directory
> `rm hadoop-3.2.1.tar.gz && cd /opt`
 	
1. Rename the hadoop directory and change its permissions
> `sudo mv hadoop-3.2.1 hadoop && sudo chown guru:guru -R hadoop` <br>
> <br>
> **NOTE: **The above command changes the owner of hadoop and files in it recursively (-R) to guru (guru:), and also changes its group to guru (:guru). See man chown for more information. mv renames directory.

1. Define hadoop home variable, and add hadoop binaries to PATH
> `echo "export HADOOP_HOME=/opt/hadoop" >> ~/.bashrc`
> `echo "export PATH=\$PATH:\$HADOOP_HOME/bin:\$HADOOP_HOME/sbin" >> ~/.bashrc`

1. Reload your bash shell and check if hadoop is installed
> `source ~/.bashrc OR . ~/bashrc` <br>
> `hadoop version`
	
1. In order for HDFS to run correctly later or, we also need to define JAVA_HOME in the file `/opt/hadoop/etc/hadoop/hadoop-env.sh`. Find the following line:
>`# export JAVA_HOME=` <br>
> <br>
> Edit it to match the following line: <br>
> `export JAVA_HOME=/home/<username>/.sdkman/candidates/java/8.0.252.hs-adpt` <br>
> <br>
> **NOTE: **Make sure to use appropriate username. Here, I replace it with guru. <br>
> **NOTE: **Make sure JAVA Version is 1.8. For me, it is the following command.<br>
> `export JAVA_HOME=/home/guru/.sdkman/candidates/java/8.0.252.hs-adpt`
	
```
I Don't think this is there. To be checked once more.


1. Export PATH of Hadoop native libraries by appending following line to .bashrc
> `export LD_LIBRARY_PATH=$HADOOP_HOME/lib/native` <br>
> <br>
> **NOTE: **Without this line, the following error will surface during runtime.
> `WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable".`<br>
> <br>
> **NOTE: **Hadoop has native implementations of certain components for performance reasons 
and for non-availability of Java implementations which are found here (libhadoop.so in *nix)
```
	
## Sources

1. [Hadoop Binaries Download](https://hadoop.apache.org/releases.html)

1. [Main](https://dev.to/awwsmm/installing-and-running-hadoop-and-spark-on-ubuntu-18-393h)

1. [Understanding '. /.bashrc'](https://stackoverflow.com/questions/2518127/how-do-i-reload-bashrc-without-logging-out-and-back-in)

1. mv (for renaming)
> man mv

1. chown
> man chown

1. [Solution to Native Library error](https://www.edureka.co/community/110/hadoop-unable-native-hadoop-library-your-platform-warning)

1. [Native Libraries necessity explanation](https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/NativeLibraries.html)

1. [LD_LIBRARY_PATH](https://stackoverflow.com/questions/40015416/spark-unable-to-load-native-hadoop-library-for-your-platform)
	
	
